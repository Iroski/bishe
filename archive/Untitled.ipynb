{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e58470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "F:\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "F:\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e7077d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a4a88fcbf4457e93826a637a1f201f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/742k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7861b13923c4dd2a541c501eaa939f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.25M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at albert-base-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
      "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer=transformers.AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "model=transformers.TFAlbertModel.from_pretrained('albert-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d15ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained('./al_to/')\n",
    "model.save_pretrained('./al_mo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aec0474",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=None\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from transformers import TFAutoModel\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e71e902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFAlbertModel.\n",
      "\n",
      "All the layers of TFAlbertModel were initialized from the model checkpoint at ./al_mo/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "inp_words_ids = Input(shape =(192,),dtype = tf.int32)\n",
    "transformer=TFAutoModel.from_pretrained('./al_mo/')\n",
    "seq_output = transformer(inp_words_ids)[0]\n",
    "cls_token = seq_output[:,0,:]\n",
    "output =  Dense(2,activation='softmax')(cls_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00712956",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model(inputs =inp_words_ids,outputs=output)\n",
    "model2.load_weights(\"albert20_192.h5\")\n",
    "tokenizer=transformers.AlbertTokenizer.from_pretrained('./al_to/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "503fba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_encode(texts,tokenizer, maxlen):\n",
    "    enc_di = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        return_attention_mask=False,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=maxlen,\n",
    "        truncation=True,\n",
    "    )\n",
    "    return np.array(enc_di[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e5d9fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2, 6256,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info='bug'\n",
    "info=[info]\n",
    "giao=quick_encode(info, tokenizer, maxlen=192)\n",
    "giao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56699f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "886    domain doc bug misconcept look node doc domain...\n",
       "488    strip type arg definit type cmd click type oft...\n",
       "265    error fail build gem nativ extens raspberri he...\n",
       "112    drive letter cannot reclaim kill process curre...\n",
       "650    nativ problem photoview plugin io plugin com-s...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df=pd.read_csv('./datasets/small_data.tsv',sep='\\t')\n",
    "train_y=train_df['label']\n",
    "train_x,val_x,train_y,val_y=train_test_split(train_df['text'],train_y,test_size=0.2,random_state=50)\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88631f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "886    domain doc bug misconcept look node doc domain...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info=train_x[:1].astype(str)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9538ed48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    2,  4603,  9765,  6256,  2462, 27724,   361, 15421,  9765,\n",
       "         4603,  2260,  2462, 27724,  4603,  2830,  4603,   584, 11608,\n",
       "           38,  4603,   302,  3003,   139,  4603, 11608,    38,  4603,\n",
       "         6711,   221,   150,  7019,  1990, 24641,  2949,  4310,   111,\n",
       "          744,  1020,  1990,  3814,  4310,   111,  1740,  5326,    49,\n",
       "         9765,  2478,  2129,  9765,  1740, 24384,   161,  4603, 11608,\n",
       "           38,  4603,   302,  3003,   139,  4603, 11608,    38,   302,\n",
       "         3003,   139, 11608,    38,  4603,  6711,   221,  7019,  8650,\n",
       "        29992,  1383,  7019,   744,  1020,   953, 20021,    38,  7030,\n",
       "          309,   891,  1320,  4861,  1287,    13,  8220,  2655,    21,\n",
       "         9507,   150,  3217,   398,    18, 10157,   538,     8,  1706,\n",
       "          702,  3893,  3814, 11158,    87,   594,  2260,   101,  1740,\n",
       "        19120,   161,  4603,    13,  8560,    38,   953, 20021,    38,\n",
       "         7030,   645,   376, 11608,    38,  4603,   302,  3003,   139,\n",
       "         4603, 11608,    38,   302,  3003,   139, 11608,    38,  4603,\n",
       "         6711,   221,  7019,  8650, 29992,  1383,  7019,   744,  1020,\n",
       "          309,   891,  1320,  4861,  1287,    13,  8220,  2655,    21,\n",
       "         9507,   150,  3217,   398,    18, 10157,   538,     8,  1706,\n",
       "          702,  3893,  3814, 11158,   953, 20021,    38,  7030,   645,\n",
       "          683,  1210, 19724, 15962,   928,  2830,  4603,   143,  1294,\n",
       "          263,    83,   166,  6681,   309,   891,  1320, 11796,  5727,\n",
       "          166,  1207,     3]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giao=quick_encode(train_x[:1].astype(str), tokenizer, maxlen=192)\n",
    "giao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7271057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=model2.predict(giao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7266ddee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][0]>result[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ee56ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
